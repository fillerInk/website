<!DOCTYPE html>
<html lang="en">
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Let us meet Vaaku2Vec!</title>
<meta name="title" content="Let us meet Vaaku2Vec!">
<meta name="description" content="Blogpost on introducing Vaaku2Vec - the state of the art
				  language modelling and text
				  classification in Malayalam">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="website">
<meta property="og:url" content="https://makers-of-kerala.now.sh/blog/meet-vaaku2vec">
<meta property="og:title" content="Let us meet Vaaku2Vec">
<meta property="og:description" content="Blogpost on introducing Vaaku2Vec - the state of the art language modelling and text classification in Malayalam">
<meta property="og:image" content="https://makers-of-kerala.now.sh/blog/vaaku2vec-card.png">

<!-- Twitter -->
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:url" content="https://makers-of-kerala.now.sh/blog/meet-vaaku2vec.html">
<meta property="twitter:title" content="Let us meet Vaaku2Vec">
<meta property="twitter:description" content="Blogpost on introducing Vaaku2Vec - the state of the art language modelling and text classification in Malayalam">
<meta property="twitter:image" content="https://makers-of-kerala.now.sh/blog/vaaku2vec-card.png">
  <link rel="stylesheet" type="text/css" href="vaaku2vec.css" />
<link href="https://fonts.googleapis.com/css?family=Work+Sans&display=swap" rel="stylesheet">
  
  <body>
    <header id="main-header">
      <h1><a id="main-title" href="/">Makers of Kerala</a></h1>
      <a href="https://twitter.com/makersofkerala">@makersofkerala</a>
    </header>

    <article>

      <header>
	<h3>Lets meet</h3>
	<h2>Vaaku2Vec</h2>
	<p>State-of-the-Art Language Modelling and Text Classification in Malayalam Language</p>
	</header>
      <div id="lang-chooser">
	<p>Choose your language:</p>
      <ul>
	<li><a href="./vaaku2vec.html">Malayalam</a></li>
	<li><a href="./vaaku2vec-mg.html">üêílish</a></li>
	<li><a class="active" href="#">English</a></li>
	</ul>
	</div>

      <section>
      <header><h2>What is Vaaku2Vec?</h2></header>
      <p>Vaak2Vec is a word embedding library written for Malayalam. It performs text classification and language modelling in Malayalam.</p>
      </section>

      <section>
      <header><h2>Word Emb... Say What?</h2></header>
      <p>
	Word Embedding is a dimensionality reduction technique in
	artificial intelligence. By studying the context in which the
	words are used, it quantifies this information and reduces it
	down to vector data. The algorithm does this by studying the
	position in which a word is embedded.

      </p>
      <p>
	In the sentence:
	"Newton sat down near the Apple tree."
	Apple is embedded between the and tree.
	The algorithm studies such embeddings and generates a vector
	notation from it. In some sense, it is a numerical representation  of the multidimensional word space structures.</p>
      </section>

      <section>
	<header><h2>Okay... that was complex, but I think I get a hang
	of it. Where do we use this?</h2></header>
	<p>The vector data so developed can aid in a number of use
	cases. Amazon recommendations can find the related products
	this way. Siri, Google Assistant, Alexa, Google Translate, or
	even smartphone keyboard with next-word prediction, then
	chances are you‚Äôve benefitted from this idea that has become
	central to Natural Language Processing models. Google search
	can use it to find out the related products. Unsurprisingly the original paper came out of the research labs in Google.</p>
	</section>

      <section>
	<header><h2>Oh interesting! Who is behind this?</h2></header>
	<p>
	  Unsurprisingly the original paper came out of the research
	  labs in Google. The original word2vec was made by:
	  Refer paper and originators
	</p>
	<p>But our own Vaaku2Vec was developed by Adam
	Shamsudeen. They have been making it better for the past 4
	years.</p>
	</section>

      <section>
	<header><h2>But if Word2Vec is there, why Vaaku2Vec?</h2></header>
	<p>As it says in the bio, Malayalam is an agglutinative
	language meaning, ithu (this) + aanu (is) = ithaanu (is
	this). Not two separate words like its English counter part. It is trained in a corpus of Newspaper data</p>
	</section>

      <section>
	<header><h2>Cool! Where do I get this?</h2></header>
	<p>Download from Github</p>
      </section>

      <section>
	<header><h2>I got it, now what?</h2></header>
	<p>Start with the suggested projects on the page by making a Github contribution.</p>
	<p>Continue reading up on this and see if you can find novel
	use cases. Read this next:</p>
	<a href="http://jalammar.github.io/illustrated-word2vec/">Illustrated Word2Vec</a>
	</section>

      <div>
	<p>If you loved the article, share the article:</p>
      </div>

      <div>
	<p>For staying in the loop, subscribe to</p>
	<a href="">Maker Broadcast</a>
      </div>

    </article>

    <footer>&copy; Makers of Kerala. 2020</footer>
    <script type="module" src="/analytics.js"></script>
  </body>
</html>
